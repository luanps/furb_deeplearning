{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T18:34:22.630204Z",
     "start_time": "2021-05-04T18:34:22.521755Z"
    },
    "hide_input": false
   },
   "source": [
    "Exercício: Implementar uma rede neural com N camadas\n",
    "        \n",
    "    - Inicializar parâmetros\n",
    "    - Forward propagation\n",
    "        - Linear\n",
    "        - Ativação (sigmoide)\n",
    "        - Custo\n",
    "    - Backpropagation - \n",
    "        - Ativação (sigmoide)\n",
    "        - Linear\n",
    "    - Atualizar parâmetros\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:57:16.747534Z",
     "start_time": "2021-05-07T22:57:13.530463Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:38:49.295993Z",
     "start_time": "2021-05-07T22:37:39.054541Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:38:49.331720Z",
     "start_time": "2021-05-07T22:38:49.303505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:38:49.521542Z",
     "start_time": "2021-05-07T22:38:49.343654Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_data = mnist['data'][mnist['target'].isin(['0','1'])]\n",
    "mnist_data = mnist_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:38:49.598152Z",
     "start_time": "2021-05-07T22:38:49.525751Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_target = mnist['target'][mnist['target'].isin(['0','1'])]\n",
    "mnist_target = np.array([int(i) for i in mnist_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:38:50.313107Z",
     "start_time": "2021-05-07T22:38:49.606824Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 11924 target: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(len(mnist_target))\n",
    "\n",
    "plt.imshow(mnist_data[i].reshape(28,28),cmap='binary')\n",
    "print(f\"\"\"i: {i} target: {mnist_target[i]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:38:50.374612Z",
     "start_time": "2021-05-07T22:38:50.345791Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_target_sample = mnist_target[:300]\n",
    "mnist_data_sample  = mnist_data[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:38:50.424383Z",
     "start_time": "2021-05-07T22:38:50.391479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 300), (1, 300))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data_sample = mnist_data_sample.T\n",
    "mnist_target_sample = mnist_target_sample.reshape(mnist_target_sample.shape[0],-1).T\n",
    "mnist_data_sample.shape, mnist_target_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:53:53.030907Z",
     "start_time": "2021-05-07T22:53:53.004444Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Ativação sigmoide\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- array numpy\n",
    "    \n",
    "    Returns:\n",
    "    A -- valor de sigmoide(z) - vetor de mesmo tamanho que Z\n",
    "    cache -- uma cópia de Z (útil para o backpropagation)\n",
    "    \"\"\"\n",
    "    #TODO: função sigmoide\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Ativação RELU\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- array numpy\n",
    "    \n",
    "    Returns:\n",
    "    A -- valor de relu(Z) - vetor de mesmo tamanho que Z\n",
    "    cache -- uma cópia de Z (útil para o backpropagation)\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: funcao RELU\n",
    "    \n",
    "    assert (dZ.shape == Z.shape) \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Derivada da função RELU (utilizada no backpropagation)\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- gradience da ativação da camada posterior\n",
    "    cache -- valor de Z guardado em cache\n",
    "    \n",
    "    Returns:\n",
    "    dZ -- gradiente em função de Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    #copia a entrada dA para dZ\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    \n",
    "    # Atualiza os valores de dZ para 0 quando Z <= 0\n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    #verifica se os vetores tem mesma dimensao\n",
    "    assert (dZ.shape == Z.shape) \n",
    "    return dZ\n",
    "\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Derivada da funcao sigmoide (utilizada no backpropagation)\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- gradience da ativação da camada posterior\n",
    "    cache -- valor de Z guardado em cache\n",
    "    \n",
    "    Returns:\n",
    "    dZ -- gradiente em função de Z\n",
    "    \"\"\"\n",
    "   \n",
    "    #TODO: derivada da função sigmoide\n",
    "    \n",
    "    \n",
    "    #verifica se os vetores tem mesma dimensao\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T23:10:20.356550Z",
     "start_time": "2021-05-07T23:10:20.330570Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_params(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- lista de inteiros onde cada elemento é o numero de nós de cada camada da rede\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dicionario python contendo os parametros \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- matriz de pesos de dimensao: (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- vetor de bias de dimensao: (layer_dims[l], 1)\n",
    "                    \n",
    "    por exemplo, dado a entrada: \n",
    "    layer_dims = [10,20,1]\n",
    "    a saida deve ser o dicionario com as seguintes matrizes:\n",
    "    parameters = {\n",
    "                  'W1': array de dimensao (20,10),\n",
    "                  'b1': array de zeros de dimensao (20,1),\n",
    "                  'W2': array de dimensao (1,20),\n",
    "                  'b2': array de zeros de dimensao (1,1),\n",
    "                  }\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    # numero de camadas na rede\n",
    "    L = len(layer_dims) \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = #TODO: inicializar pesos\n",
    "        parameters['b' + str(l)] = #TODO: inicializar bias\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T23:59:50.068072Z",
     "start_time": "2021-05-07T23:59:50.054593Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-30-44b04145c15b>, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-44b04145c15b>\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    assert (A.shape == (W.shape[0], A_prev.shape[1]))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    calculo linear do forward propagation\n",
    "    \n",
    "    Arguments:\n",
    "    A -- vetor de ativação da camada anterior (ou da camada inicial de entrada - features) \n",
    "    W -- matriz de pesos: array numpy de dimensao: (tamanho layer atual,tamanhho layer anterior)\n",
    "    b -- bias vector, numpy array de dimensao: (tamanho layer atual, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z --  (valor a ser utilizado na funcao de ativacao)\n",
    "    cache -- dicionario python contendo  \"A\", \"W\",\"b\" , utilizado no backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: funcao linear para encontrar valor de Z\n",
    "   \n",
    "    #verifica se dimensao de Z esta correta\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache\n",
    "\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Forward propagation. Esta função chama o calculo linear e a função de ativação\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Vetor de ativação da camada anterior (ou vetor de features de entrada) \n",
    "              dimensão: (tamanho layer anterior, numero de amostras)\n",
    "    W -- matriz de pesos: array numpy de dimensão (tamanho layer atual, tamanho layer anterior)\n",
    "    b -- vetor de bias: array numpy de dimensão (tamanho layer atual, 1)\n",
    "    activation -- nome da ativação a ser utilizada: string ('sigoid', 'relu')\n",
    "    \n",
    "    Returns:\n",
    "    A -- saida da função de ativação\n",
    "    cache -- dicionario python contendo \"linear_cache\" e \"activation_cache\", utilizados no backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        #TODO: chamar funcao linear\n",
    "        #TODO: chamar funcao de ativação sigmoide\n",
    "        # Entrada \"A_prev, W, b\". \n",
    "        # Saida: \"A, activation_cache\".\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        #TODO: chamar funcao linear\n",
    "        #TODO: chamar funcao de ativação relu\n",
    "        # Entrada \"A_prev, W, b\". \n",
    "        # Saida: \"A, activation_cache\".\n",
    "   \n",
    "    #verifica se dimensao de A esta correta\n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    #armazena cache\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Forward propagation \n",
    "    - para as camadas L..L-1: [LINEAR->SIGMOID/RELU]*(L-1)\n",
    "    - para a ultima camada: ->LINEAR->SIGMOID\n",
    "    \n",
    "    Arguments:\n",
    "    X -- dados, array numpy\n",
    "    parameters -- parametros de inicialização da rede (saida da função init_params() )\n",
    "    \n",
    "    Returns:\n",
    "    AL -- ultima ativação da rede\n",
    "    caches -- lista de caches\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    #numero de camadas da rede\n",
    "    L = len(parameters) // 2 \n",
    "    \n",
    "    # percorre camadas L..L-1 [LINEAR -> SIGMOID/RELU]*(L-1). \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"sigmoid\")\n",
    "        caches.append(cache)\n",
    "   \n",
    "    #ativação da ultima camada LINEAR -> SIGMOID.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches\n",
    "\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Função de custo\n",
    "    Arguments:\n",
    "    AL -- vetor de probabilidades yˆ  de dimensão (1, numero de amostras)\n",
    "    Y -- labels de dimensão (1, numero de amostras)\n",
    "    Returns:\n",
    "    cost -- custo\n",
    "    \"\"\"\n",
    "   \n",
    "    #numero de amostras\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    #TODO: calcular loss L(y^,Y)\n",
    "   \n",
    "    #transforma custo em valor unico (exemplo: [[1.3]] para 1.3)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T00:01:14.353496Z",
     "start_time": "2021-05-08T00:01:14.334137Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Função linear do backpropagation\n",
    "    \n",
    "    Arguments:\n",
    "    dZ -- Gradiente do custo em relacão a saida linear (da camada atual l)\n",
    "    cache -- tupla com valores (A_prev, W, b) (previamente computados no forward propagation da camada atual)\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradiente do custo em relação a ativação da camada anterior l-1 (mesma dimensão de A_prev)\n",
    "    dW -- Gradiente do custo em relação aos pesos(W) da camada atual l (mesma dimensão de W)\n",
    "    db -- Gradiente do custo em relação ao bias da camada attual l (mesma dimensão de b)\n",
    "    \"\"\"\n",
    "    \n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    #TODO: calcular gradiente de dW\n",
    "    \n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True) # gradiente em relação ao bias\n",
    "    \n",
    "    #TODO: calcular gradiente dA_prev (entrada: matriz W transposta, dZ)\n",
    "   \n",
    "\n",
    "    # verifica dimensões\n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Backward propagation. Esta função chama as funcoes de derivacao da ativação do calculo linear.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- Gradiente da camada atual l\n",
    "    cache -- tupla de valores de cache (linear_cache, activation_cache)\n",
    "    activation -- ativação usada na camada. string: \"sigmoid\" ou \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradiente do custo em relação a activação da camada anterior l-1. mesma dimensão de A_prev\n",
    "    dW -- Gradiente do custo em relação aos pesos(W) da camada atual l), mesma dimensão de W\n",
    "    db -- Gradient do custo em relação ao bias(b) da camada atual l), mesma dimensão de b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        #TODO: chamar funcao relu_backward\n",
    "        #TODO: chamar funcao linear_backward\n",
    "        # Entrada \"dA, activation_cache\". \n",
    "        # Saida: \"dA_prev, dW, db\".\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        #TODO: chamar funcao sigmoid_backward\n",
    "        #TODO: chamar funcao linear_backward\n",
    "        # Entrada \"dA, activation_cache\". \n",
    "        # Saida: \"dA_prev, dW, db\".\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def backprop(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Backward propagation para as camadas L..L-1 [LINEAR->SIGMOID/RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- vetor de probabilidades (y^), saida da funcao forward()\n",
    "    Y -- vetor de labels\n",
    "    caches -- lista de caches\n",
    "    \n",
    "    Returns:\n",
    "    grads -- Dicionario com os gradientes com formato:\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    #numero de camadas\n",
    "    L = len(caches) \n",
    "    #numero de amostras\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    #inicializa backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    #acessa o cache da ultima camada\n",
    "    current_cache = caches[L-1]\n",
    "    #gradiente da última camada (L)\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "   \n",
    "    #backpropagation das demais camadas (L-1..L) em ordem reversa\n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "       \n",
    "        #gradiente da camada l\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"sigmoid\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Atualiza os parâmetros da rede utilizando gradiente descendente\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- dicionario com os parametros\n",
    "    grads -- dicionario com os gradientes (saida do backpropagation)\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dicionario com os parametros atualizados no formato:\n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    #numero de camadas\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    #Loop percorrendo as camadas e atualizando os vetores de parâmetros W,b\n",
    "    for l in range(L):\n",
    "        W_updated = #TODO: atualizar os pesos (entrada: learning_rate e grads[dW l+1])\n",
    "        b_updated = #TODO: atualizar o bias (entrada: learning_rate e grads[db l+1])\n",
    "        parameters[\"W\" + str(l+1)] = W_updated\n",
    "        parameters[\"b\" + str(l+1)] = b_updated\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:38:50.745943Z",
     "start_time": "2021-05-07T22:38:50.723933Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_nn(X, Y, layers_dims, learning_rate, epochs, print_cost=False):\n",
    "    \"\"\"\n",
    "    Treinamento da rede\n",
    "    \n",
    "    Arguments:\n",
    "    X -- dados de dimensão (numero de features,numero de amostras)\n",
    "    Y -- labels anotados (0,1) de dimensao (1, numero de amostras)\n",
    "    \n",
    "    layers_dims -- lista contendo o numero de nos de cada camada\n",
    "    learning_rate -- taxa de aprendizado\n",
    "    epochs -- numero de iterações\n",
    "    print_cost -- imprime o custo a cada 100 iterações \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parâmetros aprendidos pelo modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    parameters = init_params(layers_dims)\n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        AL, caches = forward(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        grads = backprop(AL, Y, caches)\n",
    " \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (f'Cost after {i} epochs: {cost}')\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.title(f'Learning rate: {learning_rate}')\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:38:50.770108Z",
     "start_time": "2021-05-07T22:38:50.756043Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    Função de predição\n",
    "    \n",
    "    Arguments:\n",
    "    X -- dados a serem testados\n",
    "    y -- labels (para computar acurácia do modelo)\n",
    "    parameters -- parametros do modelo treinado\n",
    "    \n",
    "    Returns:\n",
    "    p -- valores preditos pelo modelo\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = forward(X, parameters)\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "            \n",
    "    acc = np.sum((p == y)/m)\n",
    "    print(f'Accuracy: {acc}')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:40:40.184618Z",
     "start_time": "2021-05-07T22:40:36.850454Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 epochs: 0.680081009313467\n",
      "Cost after 100 epochs: 0.4765518227453166\n",
      "Cost after 200 epochs: 0.394134351482421\n",
      "Cost after 300 epochs: 0.32839827195403215\n",
      "Cost after 400 epochs: 0.27877851652931224\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#params\n",
    "layers_dims = [784,30,1]\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "\n",
    "#executa o treinamento\n",
    "parameters = train_nn(mnist_data_sample, mnist_target_sample, layers_dims, learning_rate, epochs, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-07T22:40:41.964802Z",
     "start_time": "2021-05-07T22:40:41.944129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9966666666666668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(mnist_data_sample, mnist_target_sample, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
