{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T18:34:22.630204Z",
     "start_time": "2021-05-04T18:34:22.521755Z"
    },
    "hide_input": false
   },
   "source": [
    "Exercício: Implementar uma rede neural com N camadas\n",
    "        \n",
    "    - Inicializar parâmetros\n",
    "    - Forward propagation\n",
    "        - Linear\n",
    "        - Ativação (sigmoide)\n",
    "        - Custo\n",
    "    - Backpropagation - \n",
    "        - Ativação (sigmoide)\n",
    "        - Linear\n",
    "    - Atualizar parâmetros\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:11:18.742441Z",
     "start_time": "2021-05-13T11:11:14.875778Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados MNIST\n",
    "\n",
    "https://www.openml.org/d/554\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:49.327285Z",
     "start_time": "2021-05-13T11:11:18.746395Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:49.388153Z",
     "start_time": "2021-05-13T11:12:49.334833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:49.430771Z",
     "start_time": "2021-05-13T11:12:49.396134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:49.544621Z",
     "start_time": "2021-05-13T11:12:49.437356Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_data = mnist['data'][mnist['target'].isin(['0','1'])]\n",
    "mnist_data = mnist_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:49.591162Z",
     "start_time": "2021-05-13T11:12:49.547626Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_target = mnist['target'][mnist['target'].isin(['0','1'])]\n",
    "mnist_target = np.array([int(i) for i in mnist_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:52.564916Z",
     "start_time": "2021-05-13T11:12:49.595688Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 11528 target: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(len(mnist_target))\n",
    "\n",
    "plt.imshow(mnist_data[i].reshape(28,28),cmap='binary')\n",
    "print(f\"\"\"i: {i} target: {mnist_target[i]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:52.600526Z",
     "start_time": "2021-05-13T11:12:52.594559Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_target_sample = mnist_target[:300]\n",
    "mnist_data_sample  = mnist_data[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:52.656285Z",
     "start_time": "2021-05-13T11:12:52.611854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 300), (1, 300))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data_sample = mnist_data_sample.T\n",
    "mnist_target_sample = mnist_target_sample.reshape(mnist_target_sample.shape[0],-1).T\n",
    "mnist_data_sample.shape, mnist_target_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:52.683754Z",
     "start_time": "2021-05-13T11:12:52.667694Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Ativação sigmoide\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- array numpy\n",
    "    \n",
    "    Returns:\n",
    "    A -- valor de sigmoide(z) - vetor de mesmo tamanho que Z\n",
    "    cache -- uma cópia de Z (útil para o backpropagation)\n",
    "    \"\"\"\n",
    "    #TODO: função sigmoide\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Ativação RELU\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- array numpy\n",
    "    \n",
    "    Returns:\n",
    "    A -- valor de relu(Z) - vetor de mesmo tamanho que Z\n",
    "    cache -- uma cópia de Z (útil para o backpropagation)\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: funcao RELU\n",
    "    \n",
    "    assert (dZ.shape == Z.shape) \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Derivada da função RELU (utilizada no backpropagation)\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- gradience da ativação da camada posterior\n",
    "    cache -- valor de Z guardado em cache\n",
    "    \n",
    "    Returns:\n",
    "    dZ -- gradiente em função de Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    #copia a entrada dA para dZ\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    \n",
    "    # Atualiza os valores de dZ para 0 quando Z <= 0\n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    #verifica se os vetores tem mesma dimensao\n",
    "    assert (dZ.shape == Z.shape) \n",
    "    return dZ\n",
    "\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Derivada da funcao sigmoide (utilizada no backpropagation)\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- gradience da ativação da camada posterior\n",
    "    cache -- valor de Z guardado em cache\n",
    "    \n",
    "    Returns:\n",
    "    dZ -- gradiente em função de Z\n",
    "    \"\"\"\n",
    "   \n",
    "    #TODO: derivada da função sigmoide\n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    \n",
    "    #verifica se os vetores tem mesma dimensao\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:12:52.721618Z",
     "start_time": "2021-05-13T11:12:52.688117Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_params(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- lista de inteiros onde cada elemento é o numero de nós de cada camada da rede\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dicionario python contendo os parametros \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- matriz de pesos de dimensao: (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- vetor de bias de dimensao: (layer_dims[l], 1)\n",
    "                    \n",
    "    por exemplo, dado a entrada: \n",
    "    layer_dims = [10,20,1]\n",
    "    a saida deve ser o dicionario com as seguintes matrizes:\n",
    "    parameters = {\n",
    "                  'W1': array de dimensao (20,10),\n",
    "                  'b1': array de zeros de dimensao (20,1),\n",
    "                  'W2': array de dimensao (1,20),\n",
    "                  'b2': array de zeros de dimensao (1,1),\n",
    "                  }\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    # numero de camadas na rede\n",
    "    L = len(layer_dims) \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.zeros((layer_dims[l], layer_dims[l-1]))\n",
    "        #TODO: inicializar pesos\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        #TODO: inicializar bias\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:18:04.258896Z",
     "start_time": "2021-05-13T11:18:04.247078Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    calculo linear do forward propagation\n",
    "    \n",
    "    Arguments:\n",
    "    A -- vetor de ativação da camada anterior (ou da camada inicial de entrada - features) \n",
    "    W -- matriz de pesos: array numpy de dimensao: (tamanho layer atual,tamanhho layer anterior)\n",
    "    b -- bias vector, numpy array de dimensao: (tamanho layer atual, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z --  (valor a ser utilizado na funcao de ativacao)\n",
    "    cache -- dicionario python contendo  \"A\", \"W\",\"b\" , utilizado no backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: funcao linear para encontrar valor de Z\n",
    "    Z = W.dot(A) + b\n",
    "    #verifica se dimensao de Z esta correta\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache\n",
    "\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Forward propagation. Esta função chama o calculo linear e a função de ativação\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Vetor de ativação da camada anterior (ou vetor de features de entrada) \n",
    "              dimensão: (tamanho layer anterior, numero de amostras)\n",
    "    W -- matriz de pesos: array numpy de dimensão (tamanho layer atual, tamanho layer anterior)\n",
    "    b -- vetor de bias: array numpy de dimensão (tamanho layer atual, 1)\n",
    "    activation -- nome da ativação a ser utilizada: string ('sigoid', 'relu')\n",
    "    \n",
    "    Returns:\n",
    "    A -- saida da função de ativação\n",
    "    cache -- dicionario python contendo \"linear_cache\" e \"activation_cache\", utilizados no backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        #TODO: chamar funcao linear\n",
    "        #TODO: chamar funcao de ativação sigmoide\n",
    "        # Entrada \"A_prev, W, b\". \n",
    "        # Saida: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        pass\n",
    "        #TODO: chamar funcao linear\n",
    "        #TODO: chamar funcao de ativação relu\n",
    "        # Entrada \"A_prev, W, b\". \n",
    "        # Saida: \"A, activation_cache\".\n",
    "   \n",
    "    #verifica se dimensao de A esta correta\n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    #armazena cache\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Forward propagation \n",
    "    - para as camadas L..L-1: [LINEAR->SIGMOID/RELU]*(L-1)\n",
    "    - para a ultima camada: ->LINEAR->SIGMOID\n",
    "    \n",
    "    Arguments:\n",
    "    X -- dados, array numpy\n",
    "    parameters -- parametros de inicialização da rede (saida da função init_params() )\n",
    "    \n",
    "    Returns:\n",
    "    AL -- ultima ativação da rede\n",
    "    caches -- lista de caches\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    #numero de camadas da rede\n",
    "    L = len(parameters) // 2 \n",
    "    \n",
    "    # percorre camadas L..L-1 [LINEAR -> SIGMOID/RELU]*(L-1). \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"sigmoid\")\n",
    "        caches.append(cache)\n",
    "   \n",
    "    #ativação da ultima camada LINEAR -> SIGMOID.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches\n",
    "\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Função de custo\n",
    "    Arguments:\n",
    "    AL -- vetor de probabilidades yˆ  de dimensão (1, numero de amostras)\n",
    "    Y -- labels de dimensão (1, numero de amostras)\n",
    "    Returns:\n",
    "    cost -- custo\n",
    "    \"\"\"\n",
    "   \n",
    "    #numero de amostras\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    #TODO: calcular loss L(y^,Y)\n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "   \n",
    "    #transforma custo em valor unico (exemplo: [[1.3]] para 1.3)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:18:08.815563Z",
     "start_time": "2021-05-13T11:18:08.798857Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Função linear do backpropagation\n",
    "    \n",
    "    Arguments:\n",
    "    dZ -- Gradiente do custo em relacão a saida linear (da camada atual l)\n",
    "    cache -- tupla com valores (A_prev, W, b) (previamente computados no forward propagation da camada atual)\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradiente do custo em relação a ativação da camada anterior l-1 (mesma dimensão de A_prev)\n",
    "    dW -- Gradiente do custo em relação aos pesos(W) da camada atual l (mesma dimensão de W)\n",
    "    db -- Gradiente do custo em relação ao bias da camada attual l (mesma dimensão de b)\n",
    "    \"\"\"\n",
    "    \n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    #TODO: calcular gradiente de dW\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True) # gradiente em relação ao bias\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    #TODO: calcular gradiente dA_prev (entrada: matriz W transposta, dZ)\n",
    "   \n",
    "\n",
    "    # verifica dimensões\n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Backward propagation. Esta função chama as funcoes de derivacao da ativação do calculo linear.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- Gradiente da camada atual l\n",
    "    cache -- tupla de valores de cache (linear_cache, activation_cache)\n",
    "    activation -- ativação usada na camada. string: \"sigmoid\" ou \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradiente do custo em relação a activação da camada anterior l-1. mesma dimensão de A_prev\n",
    "    dW -- Gradiente do custo em relação aos pesos(W) da camada atual l), mesma dimensão de W\n",
    "    db -- Gradient do custo em relação ao bias(b) da camada atual l), mesma dimensão de b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        pass\n",
    "        #TODO: chamar funcao relu_backward\n",
    "        #TODO: chamar funcao linear_backward\n",
    "        # Entrada \"dA, activation_cache\". \n",
    "        # Saida: \"dA_prev, dW, db\".\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "        #TODO: chamar funcao sigmoid_backward\n",
    "        #TODO: chamar funcao linear_backward\n",
    "        # Entrada \"dA, activation_cache\". \n",
    "        # Saida: \"dA_prev, dW, db\".\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def backprop(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Backward propagation para as camadas L..L-1 [LINEAR->SIGMOID/RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- vetor de probabilidades (y^), saida da funcao forward()\n",
    "    Y -- vetor de labels\n",
    "    caches -- lista de caches\n",
    "    \n",
    "    Returns:\n",
    "    grads -- Dicionario com os gradientes com formato:\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    #numero de camadas\n",
    "    L = len(caches) \n",
    "    #numero de amostras\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    #inicializa backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    #acessa o cache da ultima camada\n",
    "    current_cache = caches[L-1]\n",
    "    #gradiente da última camada (L)\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "   \n",
    "    #backpropagation das demais camadas (L-1..L) em ordem reversa\n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "       \n",
    "        #gradiente da camada l\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"sigmoid\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Atualiza os parâmetros da rede utilizando gradiente descendente\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- dicionario com os parametros\n",
    "    grads -- dicionario com os gradientes (saida do backpropagation)\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dicionario com os parametros atualizados no formato:\n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    #numero de camadas\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    #Loop percorrendo as camadas e atualizando os vetores de parâmetros W,b\n",
    "    for l in range(L):\n",
    "        #TODO: atualizar os pesos (entrada: learning_rate e grads[dW l+1])\n",
    "        W_updated = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        #TODO: atualizar o bias (entrada: learning_rate e grads[db l+1])\n",
    "        b_updated = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        parameters[\"W\" + str(l+1)] = W_updated\n",
    "        parameters[\"b\" + str(l+1)] = b_updated\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:18:11.451505Z",
     "start_time": "2021-05-13T11:18:11.432770Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_nn(X, Y, layers_dims, learning_rate, epochs, print_cost=False):\n",
    "    \"\"\"\n",
    "    Treinamento da rede\n",
    "    \n",
    "    Arguments:\n",
    "    X -- dados de dimensão (numero de features,numero de amostras)\n",
    "    Y -- labels anotados (0,1) de dimensao (1, numero de amostras)\n",
    "    \n",
    "    layers_dims -- lista contendo o numero de nos de cada camada\n",
    "    learning_rate -- taxa de aprendizado\n",
    "    epochs -- numero de iterações\n",
    "    print_cost -- imprime o custo a cada 100 iterações \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parâmetros aprendidos pelo modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    parameters = init_params(layers_dims)\n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        AL, caches = forward(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        grads = backprop(AL, Y, caches)\n",
    " \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (f'Cost after {i} epochs: {cost}')\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.title(f'Learning rate: {learning_rate}')\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:18:12.407275Z",
     "start_time": "2021-05-13T11:18:12.388363Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    Função de predição\n",
    "    \n",
    "    Arguments:\n",
    "    X -- dados a serem testados\n",
    "    y -- labels (para computar acurácia do modelo)\n",
    "    parameters -- parametros do modelo treinado\n",
    "    \n",
    "    Returns:\n",
    "    p -- valores preditos pelo modelo\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = forward(X, parameters)\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "            \n",
    "    acc = np.sum((p == y)/m)\n",
    "    print(f'Accuracy: {acc}')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:18:18.937408Z",
     "start_time": "2021-05-13T11:18:15.996539Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 epochs: 0.6931471805599453\n",
      "Cost after 100 epochs: 0.5711569675360915\n",
      "Cost after 200 epochs: 0.48042405661622906\n",
      "Cost after 300 epochs: 0.43145673881149427\n",
      "Cost after 400 epochs: 0.4011879367798027\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtnklEQVR4nO3deXwV9b3/8dcnGxB2SJCdsCkKokBYg63WDW0Ft2txQQEtakVte1uvtr97bfV6a29XK1ZFBRQX3L1otS5Vq4BAgiDIHnaQJZCwBkgIn98fZ7DH9AABcjLJyfv5eMzDc2a+c+adwZNPZuY73zF3R0REpLyksAOIiEj1pAIhIiIxqUCIiEhMKhAiIhKTCoSIiMSkAiEiIjGpQEitZWZnmdnSsHOIVFcqEBIKM1ttZueFmcHdP3X3U8LMcIiZnW1m6yv5M881syVmVmxmH5lZhyO0zQraFAfrnFdu+Y/NbJOZ7TSzCWZWJ2rZ/Wa2wMwOmNkvK/NnkHCpQEjCMrPksDMAWESVftfMLAN4DfhPoBmQB7x4hFVeAOYCzYFfAK+YWWbwWRcCdwPnAh2ATsCvotbNB+4C/lq5P4WETQVCqhUzSzKzu81shZltM7OXzKxZ1PKXg79kd5jZJ2bWPWrZJDN71MzeNrM9wDnBkcpPzWx+sM6LZlY3aP+Nv9qP1DZYfpeZbTSzr8zsJjNzM+tymJ/jYzN7wMymA8VAJzMbZWaLzWyXma00s5uDtvWBd4DWZrY7mFofbV8cxeXAQnd/2d33Ab8EzjCzbjGyngz0Bu51973u/iqwALgiaHID8JS7L3T3IuB+YOSh9d39aXd/B9hVwWxSQ6hASHVzO3Ap8G2gNVAEPBK1/B2gK9AC+Bx4rtz61wAPAA2BacG8q4AhQEegJ1G/3GKI2dbMhgA/Ac4DugBnV+BnGQGMCbKsAbYA3wMaAaOAP5pZb3ffA1wEfOXuDYLpq6Pti6CQXXOYbXcHvjj0JtjGimB+rLYr3T36F/wXUW2/8VnB65PMrPlR94DUaClhBxAp5xZgrLuvBwjOaa81sxHufsDdJxxqGCwrMrPG7r4jmP1/7j49eL3PzAD+HPzCxczeBM48wvYP1/YqYKK7L4za9rVH+VkmHWofiD4F8w8zew84i0ihi+Vo+6LnEbbdACgoN28HkWIVq+2OGG3bHGb5odcNgW1HyCA1nI4gpLrpALxuZtvNbDuwGCgj8hdrspk9GJxy2QmsDtbJiFp/XYzP3BT1upjIL7zDOVzb1uU+O9Z2yvtGGzO7yMxmmllh8LNdzDezl3fYfVGBbe8mcqQSrRGxTwMdrW355Yde65RSglOBkOpmHXCRuzeJmuq6+wYip4+GETnN0xjICtaxqPXjNTzxRqBt1Pt2FVjn6yxBr59Xgd8BJ7l7E+Bt/pk9Vu4j7YujWQicEbX9+kDnYH6stp3MLPro4oyott/4rOD1ZnfX0UOCU4GQMKWaWd2oKQV4DHjgUJdMM8s0s2FB+4bAfiKnNdKB/6nCrC8Bo8zsVDNLJ9I76FikAXWInPY5YGYXARdELd8MNDezxlHzjrQvjuZ1oIeZXRFcaP8vYL67Lynf0N2XAfOAe4N/h8uIXH95NWjyDHCjmZ1mZk2A/wdMOrS+maUG20gCUoLPqBY9yOTEqEBImN4G9kZNvwQeAqYC75nZLmAm0D9o/wyRi70bgEXBsioR9NL5M/ARkW6dh7a9v4Lr7wLuIFJoiogcDU2NWr6ESFfTlcEppdYceV9gZgvNLOZ1EHcvINIL6YFge/2B4VHrPmZmj0WtMhzIDto+CFwZfAbu/jfgf4OffS2Rf4N7o9Z9gsi/39VEusjuJXKBXmo40wODRI6dmZ0KfAnUcfcDYecRiQcdQYhUkJldZmZ1zKwp8BvgTRUHSWQqECIVdzORexlWEOlNdGu4cUTiS6eYREQkJh1BiIhITAlzJ3VGRoZnZWWFHUNEpEaZM2fOVnfPjLUsYQpEVlYWeXl5YccQEalRzGzN4ZbF9RSTmQ0xs6Vmlm9md8dY/kczmxdMy4LhBA4tu8HMlgfTDfHMKSIi/ypuRxDBnZSPAOcD64FcM5vq7osOtXH3H0e1vx3oFbxuRuRGnGwiQxDMCdYtildeERH5pngeQfQD8t19pbuXAFOIjKNzOFcTuZMU4ELgfXcvDIrC+0SGYBYRkSoSzwLRhm+OZrmefw4f/A3BWDMdgQ+PdV0REYmP6tLNdTjwiruXHctKZjbGzPLMLK+goPzQ9yIiciLiWSA28M0hkdsG82IZzj9PL1V4XXcf7+7Z7p6dmRmzl5aIiByneBaIXKCrmXU0szQiRWBq+UbBM3KbAp9FzX4XuMDMmgbj3lwQzBMRkSoStwIRDGI2lsgv9sXAS+6+0MzuM7OhUU2HA1M8aswPdy8k8mD03GC6L5hX6Q6UHeR/3l7Mhu174/HxIiI1VsKMxZSdne3Hc6Pc6q17uGTcNDIb1uHlmwfSvEGdOKQTEamezGyOu2fHWlZdLlKHJiujPhNG9mVD0V5GTsxl936N3iwiAioQAPTNasaj1/Vm0cadjHkmj32lx9SZSkQkIalABL7T7SR+9289mbFiGz+aMo+yg4lx6k1E5HipQES5rFdb7r3kNP62cBO/eH0BiXJ9RkTkeCTMaK6VZVROR4r2lPDnD/NpWj+N/xjSLexIIiKhUIGI4cfnn8y2PSU8+vEKmqanMuZbncOOJCJS5VQgYjAz7hvWg+17S/mft5fQJD2Nq7LbHX1FEZEEogJxGMlJxh+vOpOde0u5+9X5NK6XyoXdW4YdS0Skyugi9RGkpSTx2HV96Nm2Cbe/MJfPVmwLO5KISJVRgTiK+nVSmDiyLx2apfODZ/L4csOOsCOJiFQJFYgKaFo/jWdu7EfjeqncMGE2Kwt2hx1JRCTuVCAqqFXjeky+sR8AI56azaYd+0JOJCISXyoQx6BTZgMmjerHjr2ljHhqFtuLS8KOJCISNyoQx+j0to154vps1hQWM3JiLns0uJ+IJCgViOMwsHNzHr66F/PXb+eWZ+dQcuBg2JFERCqdCsRxurB7Sx68oiefLt/KT17S4H4iknh0o9wJuCq7HUV7Svj1O0tomp7GfcO6Y2ZhxxIRqRQqECfo5m93prC4hMf/sZKm9dP4yfknhx1JRKRSqEBUgruHdGP7nlL+/PflNE1PZVROx7AjiYicMBWISmBmPHBZD7bvLeFXby6iaXoal/ZqE3YsEZEToovUlSQlOYmHhvdiYKfm/PTlL/hwyeawI4mInBAViEpUNzWZ8df34dRWjfjhc5+Tt7ow7EgiIsdNBaKSNaybyqRRfWnduB6jJ+WyeOPOsCOJiBwXFYg4aN6gDs/c2I/0tBSunzCbtduKw44kInLMVCDipG3TdCbf2I/SsoNc99QstuzS4H4iUrPEtUCY2RAzW2pm+WZ292HaXGVmi8xsoZk9HzW/zMzmBdPUeOaMl64nNWTiyL5s3b2f65+azY69pWFHEhGpsLgVCDNLBh4BLgJOA642s9PKtekK3APkuHt34EdRi/e6+5nBNDReOeOtV/umPD6iDysKdnPT07nsLSkLO5KISIXE8wiiH5Dv7ivdvQSYAgwr1+YHwCPuXgTg7lvimCc0Z3XN5E/f70XemiJue/5zSss0uJ+IVH/xLBBtgHVR79cH86KdDJxsZtPNbKaZDYlaVtfM8oL5l8bagJmNCdrkFRQUVGr4yvbdnq3470t78OGSLdz1ynwOanA/Eanmwr6TOgXoCpwNtAU+MbPT3X070MHdN5hZJ+BDM1vg7iuiV3b38cB4gOzs7Gr/G/fa/h0o2lPC795bRpP0VP7re6dpcD8RqbbiWSA2AO2i3rcN5kVbD8xy91JglZktI1Iwct19A4C7rzSzj4FewApquNvO6ULhnlImTF9F8/ppjP1O17AjiYjEFM9TTLlAVzPraGZpwHCgfG+kN4gcPWBmGUROOa00s6ZmVidqfg6wKI5Zq4yZ8f++eyqX92rD795bxrMz14QdSUQkprgdQbj7ATMbC7wLJAMT3H2hmd0H5Ln71GDZBWa2CCgDfubu28xsEPC4mR0kUsQedPeEKBAASUnGb67syY69pfzn/31Jk/RUvtezddixRES+wdyr/an7CsnOzva8vLywYxyTfaVlXP/UbOauK+KpG/ryrZMzw44kIrWMmc1x9+xYy3QndYjqpibzxA3ZdGnRkJsnz2Hu2qKwI4mIfE0FImSN66Xy9Oi+tGhUh1GTclm+eVfYkUREABWIaqFFw7pMHt2f1OQkRjw1m/VFGtxPRMKnAlFNtG+ezjOj+1FccoDrn5rN1t37w44kIrWcCkQ1cmqrRkwY2Zevduxl5MTZ7Nqnwf1EJDwqENVMdlYzHr22D0s27uIHz+Sxr1SD+4lIOFQgqqFzurXgd/92BjNXFnLHC3M5oMH9RCQEKhDV1KW92nDvJafx3qLN/Pz1BSTK/SoiUnOEPVifHMGonI4UFZfy578vp2n9NO656NSwI4lILaICUc39+LyuFO0p4fF/rKRpehq3fLtz2JFEpJZQgajmzIxfDe3O9r2lPPjOEpqmp/L9vu3DjiUitYAKRA2QlGT8/t/OYMfeUu55bQGN66UxpEfLsGOJSILTReoaIi0liceu680Z7ZpwxwtzmbFia9iRRCTBqUDUIOlpKUwc2ZesjHR+8HQeC9bvCDuSiCQwFYgapkl6Gs+M7k+T9DRumDibFQW7w44kIglKBaIGatm4Ls/e1B8Drn9qNht37A07kogkIBWIGqpjRn2eHt2PnXtLGfHUbIr2lIQdSUQSjApEDdajTWOeuCGbtYXFjJyUy579B8KOJCIJRAWihhvQqTnjru7FgvXbueXZOew/oMH9RKRyqEAkgAu6t+TBK3ry6fKt/OTFLyg7qHGbROTE6Ua5BHFVdjt2FJfywNuLaZyeygOX9sDMwo4lIjWYCkQC+cG3OlFYXMKjH6+gef00/v2CU8KOJCI1mApEgrnrwlMo2lPCwx/m0yQ9jRsHdww7kojUUCoQCcbMeOCy09leXMr9by2iaXoql/duG3YsEamBdJE6ASUnGQ9dfSaDOjfnZ6/M54NFm8OOJCI1UFwLhJkNMbOlZpZvZncfps1VZrbIzBaa2fNR828ws+XBdEM8cyaiOinJjL8+m+6tG3Hb858ze1Vh2JFEpIaJW4Ews2TgEeAi4DTgajM7rVybrsA9QI67dwd+FMxvBtwL9Af6AfeaWdN4ZU1UDepEBvdr07QeN07KZdFXO8OOJCI1SDyPIPoB+e6+0t1LgCnAsHJtfgA84u5FAO6+JZh/IfC+uxcGy94HhsQxa8Jq3qAOk2/sT4O6KVw/YTZrtu0JO5KI1BDxLBBtgHVR79cH86KdDJxsZtPNbKaZDTmGdTGzMWaWZ2Z5BQUFlRg9sbRpUo/JN/aj7OBBrntqFlt27gs7kojUAGFfpE4BugJnA1cDT5hZk4qu7O7j3T3b3bMzMzPjkzBBdGnRkEmj+rFtdwnXT5jNjuLSsCOJSDUXzwKxAWgX9b5tMC/aemCqu5e6+ypgGZGCUZF15Rid0a4J40dks7JgD6OfzmVvicZtEpHDi2eByAW6mllHM0sDhgNTy7V5g8jRA2aWQeSU00rgXeACM2saXJy+IJgnJ2hw1wz+NPxMPl9bxK3PzaG07GDYkUSkmopbgXD3A8BYIr/YFwMvuftCM7vPzIYGzd4FtpnZIuAj4Gfuvs3dC4H7iRSZXOC+YJ5UgotPb8UDl57Ox0sL+OnLX3BQg/uJSAzmnhi/HLKzsz0vLy/sGDXKIx/l89t3lzJyUBb3XnKaBvcTqYXMbI67Z8dapqE2arEfnt2Zoj0lPDltFc3qp3HHuV3DjiQi1YgKRC1mZvz84lMpKi7lD+8vo2l6KiMGZoUdS0SqCRWIWi4pyfjNFaezY28J/zV1IY3T0xh6RuuwY4lINRD2fRBSDaQkJzHumt707dCMn7w4j4+Xbjn6SiKS8FQgBIC6qck8OTKbric15NZnP2fOmqKwI4lIyFQg5GuN6qbyzOh+nNSoDqMn5bJs866wI4lIiFQg5BsyG0YG96uTksSIp2axrrA47EgiEhIVCPkX7ZqlM/nG/uwtKWPEU7Mo2LU/7EgiEgIVCInplJYNmTiqL5t27mPkxNns3KfB/URqGxUIOaw+HZrx6HV9WLppFzc9nce+Ug3uJ1KbqEDIEZ1zSgt+f9UZ5K4uZOzzczmgwf1Eag0VCDmqYWe24ZeXdOeDxZu5+7UFJMr4XSJyZLqTWirkhkFZFBWX8KcPltM0PZWfX3yqBvcTSXAqEFJhd57blaI9JTzx6SqSzLhrSDeSk1QkRBKVCoRUmJlx7yXdKXPn8U9WsnTzLh4a3ovG9VLDjiYicaBrEHJMkpKM/770dB64rAfT87dy6SPTWa47rkUSkgqEHJdr+3fg+R8MYNe+A1z2lxm8t3BT2JFEpJKpQMhx65vVjDdvz6FTZn3GTJ7DQx8s1+NLRRKICoSckFaN6/HSzQO5vFcb/vjBMm59bg679x8IO5aIVAIVCDlhdVOT+f1VZ/Cf3zuNDxZv4fK/TGf11j1hxxKRE6QCIZXCzLhxcEeeGd2PLbv2M3TcNP6xrCDsWCJyAlQgpFLldMlg6m2Dad2kHqMmzubxf6zQndciNVSFCoSZ/VtF5okAtG+ezms/HMRFPVrx63eWcOeUeewt0UB/IjVNRY8g7qngPBEA0tNSGHdNL3524Sm8Of8rrnxsBuuL9PAhkZrkiHdSm9lFwMVAGzP7c9SiRoC6qsgRmRm3ndOFU1s15M4X5jF03HT+cm1vBnRqHnY0EamAox1BfAXkAfuAOVHTVODCo324mQ0xs6Vmlm9md8dYPtLMCsxsXjDdFLWsLGr+1GP5oaR6+U63k3hjbA5N01O57slZPPPZal2XEKkBrCJfVDNLdffS4HVToJ27zz/KOsnAMuB8YD2QC1zt7oui2owEst19bIz1d7t7g4r+INnZ2Z6Xl1fR5hKCnftK+cmL8/hg8Rauym7L/Zf2oE5KctixRGo1M5vj7tmxllX0GsT7ZtbIzJoBnwNPmNkfj7JOPyDf3Ve6ewkwBRhW4dSScBrVTWX8iGxu/04XXspbz/DxM9m8c1/YsUTkMCpaIBq7+07gcuAZd+8PnHuUddoA66Lerw/mlXeFmc03s1fMrF3U/LpmlmdmM83s0lgbMLMxQZu8ggL1ua8JkpKMf7/gFB69tjdLN+3ikoen8fnaorBjiUgMFS0QKWbWCrgKeKsSt/8mkOXuPYH3gaejlnUIDnuuAf5kZp3Lr+zu4909292zMzMzKzGWxNtFp7fitR8Oom5qMsMfn8lLueuOvpKIVKmKFoj7gHeBFe6ea2adgOVHWWcDEH1E0DaY9zV33+bu+4O3TwJ9opZtCP67EvgY6FXBrFJDdGvZiKljc+jXsRl3vTqfe//vS0r1zGuRaqNCBcLdX3b3nu5+a/B+pbtfcZTVcoGuZtbRzNKA4UR6P30tOCo5ZCiwOJjf1MzqBK8zgBxgEZJwmqSnMWlUX35wVkee/mwN1z05i2279x99RRGJu4reSd3WzF43sy3B9KqZtT3SOu5+ABhL5MhjMfCSuy80s/vMbGjQ7A4zW2hmXwB3ACOD+acCecH8j4AHo3s/SWJJSU7iF989jT9+/wzmrdvO0HHT+XLDjrBjidR6Fe3m+j7wPDA5mHUdcK27nx/HbMdE3VwTw4L1O7h5ch6FxSX85oqeDDszVr8GEaksldHNNdPdJ7r7gWCaBOiqsFS609s2Zurtg+nZpgl3TpnHr99eTJkeQiQSiooWiG1mdp2ZJQfTdcC2eAaT2iujQR2evak/IwZ04PFPVjJy4mx2FJeGHUuk1qlogRhNpIvrJmAjcCX/vF4gUunSUpK4/9IePHj56cxcuY2hj0xj2eZdYccSqVWOpZvrDe6e6e4tiBSMX8UvlkjE8H7tmTJmAMUlZVz2yHTeXbgp7EgitUZFC0RPd//6dld3L0T3JUgV6dOhGW+OHUyXkxpy8+Q5/PH9ZRzUdQmRuKtogUgKBukDIBiT6YhDhYtUppaN6/LimAFc2actD/19OTc/O4dd+3RdQiSeKlogfg98Zmb3m9n9wAzgf+MXS+Rf1U1N5rdX9uTeS07jwyVbuOwvM1i1dU/YsUQSVkXvpH6GyEB9m4PpcneffOS1RCqfmTEqpyOTb+zHtt37GTpuGh8t3RJ2LJGEVNEjCNx9kbuPCybd1SyhGtQ5g6ljB9O2aTqjJ+Xyl4/z9RAikUpW4QIhUt20a5bOq7cO5Lunt+J//7aU21+YS3GJnoQrUllUIKRGS09L4eGre/EfQ7rx1wUbueLRz1hXWBx2LJGEoAIhNZ6ZcevZnZk4si/ri4oZOm4aM1ZsDTuWSI2nAiEJ4+xTWjB17GCaN6jDiKdmM3H6Kl2XEDkBKhCSUDpm1Of1Hw7inFNa8Ks3F/GzV+azr7Qs7FgiNZIKhCSchnVTGT+iD3ee25VX5qzn++NnsmnHvrBjidQ4KhCSkJKSjB+ffzKPXdeH/M27uGTcNOasKQw7lkiNogIhCW1Ij5a8flsO6WnJDB8/kymz14YdSaTGUIGQhHfySQ2ZettgBnRqzt2vLeA/3/iSkgMHw44lUu2pQEit0Dg9lUmj+nHztzoxeeYarntyFlt37w87lki1pgIhtUZyknHPxafy0PAz+WL9di55eBoL1u8IO5ZItaUCIbXOsDPb8Oqtg0gy48rHZvDG3A1hRxKpllQgpFbq0aYxU8fmcGa7JvzoxXn891uLOFCm6xIi0VQgpNZq3qAOz97UnxsGduDJaasYNSmX7cUlYccSqTZUIKRWS01O4lfDevC/V/Rk1spCho6bzpJNO8OOJVItqECIAFf1bceUmwewr7SMy/8yg3cWbAw7kkjo4logzGyImS01s3wzuzvG8pFmVmBm84LppqhlN5jZ8mC6IZ45RQB6t2/Km7cP5pSWDbn1uc/5/XtLOXhQg/1J7RW3AmFmycAjwEXAacDVZnZajKYvuvuZwfRksG4z4F6gP9APuNfMmsYrq8ghJzWqy5QxA7gquy0Pf5jPmMl57NpXGnYskVDE8wiiH5Dv7ivdvQSYAgyr4LoXAu+7e6G7FwHvA0PilFPkG+qkJPObK3py37DufLy0gEsfmc6Kgt1hxxKpcvEsEG2AdVHv1wfzyrvCzOab2Stm1u5Y1jWzMWaWZ2Z5BQUFlZVbBDPj+oFZPHtTf4qKS7l03HQ+XLI57FgiVSrsi9RvAlnu3pPIUcLTx7Kyu49392x3z87MzIxLQKndBnRqztSxObRvns6NT+fxyEf5egiR1BrxLBAbgHZR79sG877m7tvc/dCAOE8CfSq6rkhVads0nVduGcQlPVvz23eXctvzn7Nn/4GwY4nEXTwLRC7Q1cw6mlkaMByYGt3AzFpFvR0KLA5evwtcYGZNg4vTFwTzREJRLy2Zh4afyc8v7sbfvtzEFY/OYF1hcdixROIqbgXC3Q8AY4n8Yl8MvOTuC83sPjMbGjS7w8wWmtkXwB3AyGDdQuB+IkUmF7gvmCcSGjNjzLc6M3FUP77avpdLxk1jev7WsGOJxI0lyvnU7Oxsz8vLCzuG1BKrt+5hzOQ8VhTs4ecXn8ronCzMLOxYIsfMzOa4e3asZWFfpBapkbIy6vPaD3M479QW3P/WIv795S/YV1oWdiyRSqUCIXKcGtRJ4dFr+/Dj807mtc83cNXjn7Fxx96wY4lUGhUIkROQlGTceV5Xxo/ow4otu7nk4enkrdblMkkMKhAileCC7i1547YcGtZN4eonZvLcrDVhRxI5YSoQIpWk60kNeeO2HAZ1zuAXr3/Jz19fQMkBPYRIai4VCJFK1LheKhNG9uWWb3fm+VlrueaJmWzZtS/sWCLHRQVCpJIlJxl3X9SNh6/uxZdf7WDow9P5eOkWDdEhNY4KhEicXHJGa169dRCpKcbIiblc+KdPeH7WWvaWqDus1Ay6UU4kzvYfKOPNLzYyYdoqFm3cSZP0VK7u157rB3agVeN6YceTWu5IN8qpQIhUEXdn9qpCJk5fzXuLNmFmXNSjJaMHd6R3ez0PS8JxpAKRUtVhRGorM6N/p+b079ScdYXFPD1jNS/mruOt+Rs5s10TRuVkcfHprUhN1plfqR50BCESot37D/DqnPVMmrGaVVv30LJRXUYM7MDV/drTrH5a2PGkFtApJpFq7uBB5+NlW5g4fTWfLt9KnZQkLuvVhlE5HTmlZcOw40kC0ykmkWouKcn4TreT+E63k1i2eRcTp6/mtc/XMyV3HTldmjM6pyPnnNKCpCSNGCtVR0cQItVU0Z4SXshdyzMz1rBp5z6ymqczclAWV2a3o0Ed/W0nlUOnmERqsNKyg/zty01MmL6KuWu307BOClf1bcfIQVm0a5Yedjyp4VQgRBLE3LVFTJy+mrcXbOSgO+edehKjB3ekf8dmemCRHBcVCJEEs2nHPibPXM3zs9ZSVFzKqa0aMToni0vOaE3d1OSw40kNogIhkqD2lZbxxtwNTJi+imWbd9O8fhrXDujAdQPa06Jh3bDjSQ2gAiGS4NydGSu2MWHaKv6+ZAupycYlPVszKqcjp7dtHHY8qcbUzVUkwZkZOV0yyOmSwaqte3h6xmpezlvHa3M30DerKaNzOnL+aSeRoru05RjoCEIkQe3cV8pLuet4+rPVrCvcS5sm9bhhUAe+n92exumpYceTakKnmERqsbKDzgeLNzNh2ipmrSqkXmoyV/Zpy8icLDpnNgg7noRMBUJEAFj41Q4mTl/N1HlfUVJ2kLNPyWR0TkfO6pqhbrK1lAqEiHxDwa79PD9rLZNnrmHr7v10adGAUTlZXN6rLfXS1E22NjlSgYjrFSszG2JmS80s38zuPkK7K8zMzSw7eJ9lZnvNbF4wPRbPnCK1TWbDOtx5Xlem330Of7jqDOqmJvGL179kwK//zoPvLOGr7XvDjijVQNyOIMwsGVgGnA+sB3KBq919Ubl2DYG/AmnAWHfPM7Ms4C1371HR7ekIQuT4uTt5a4qYMG0V7y6MPMxoSI+WjM7pSO/2TXT6KYGF1c21H5Dv7iuDEFOAYcCicu3uB34D/CyOWUTkCMyMvlnN6JvVjPVFxTzz2RqmzF7LX+dv5Iy2jRk9uCMX9WhFWoq6ydYm8fzXbgOsi3q/Ppj3NTPrDbRz97/GWL+jmc01s3+Y2VmxNmBmY8wsz8zyCgoKKi24SG3Wtmk6P7/4VD6751zuH9adXfsPcOeUeQz+zYeM+3A523bvDzuiVJHQbpQzsyTgD8DIGIs3Au3dfZuZ9QHeMLPu7r4zupG7jwfGQ+QUU5wji9Qq9eukMGJgFtf278A/lhcwcfpqfvfeMv78YT6XndmGUYOz6NayUdgxJY7iWSA2AO2i3rcN5h3SEOgBfByc32wJTDWzoe6eB+wHcPc5ZrYCOBnQRQaRKpaUZJxzSgvOOaUF+VsiDzN69fP1vJi3jkGdIw8z+k43PcwoEcXzInUKkYvU5xIpDLnANe6+8DDtPwZ+GlykzgQK3b3MzDoBnwKnu3vh4bani9QiVWd7cQlTctfx9IzVbNyxjw6HHmbUpy0N6+ou7ZoklG6u7n4AGAu8CywGXnL3hWZ2n5kNPcrq3wLmm9k84BXgliMVBxGpWk3S07jl25355K5zGHdNLzIa1OFXby5i4K8/5L43F7F2W3HYEaUS6EY5EakUX6zbzsTpq3hr/kbKgocZjcrJYmCn5uomW43pTmoRqTKbd+7j2ZlreG7WWgr3lNCtZUNGD+7IUD3MqFpSgRCRKrevtIyp875iwvRVLNm0i+b107imf3tGDOhAi0Z6mFF1oQIhIqFxdz5bsY0J01fz9yWbSUkyvtezNaNysujZtknY8Wo9PTBIREJjZgzqksGgLhms2baHSTNW83Leel6fu4HsDk0ZldORC7vrYUbVkY4gRKTK7dpXyst565k0YzVrC4tp3bgu1w/KYnjfdjRJTws7Xq2iU0wiUi2VHXQ+XLKFCdNW8dnKbdRLTeby3m24KrsdPdo0Jlk338WdCoSIVHuLN+5k4vRVvDHvK0oOHKRJeiqDOjdncJdMzuqaQbtm6WFHTEgqECJSYxTtKeGT5QV8unwr05ZvZdPOfQB0aJ7O4C4ZnNU1g4GdM2hcT3dsVwYVCBGpkdydFQW7vy4WM1duY09JGUkGPds24ayuGQzukkGv9k01FPlxUoEQkYRQWnaQuWu3M215AZ/mb+WLdds56JCelsyATs2/PsLo0qKB7t6uIBUIEUlIO/aWMnPlNqYt38q0/K2s2roHgJMa1SEnKBY5XTJo0VA35h2OCoSI1Arri4qZtnwrn+ZvZUb+VoqKSwHo1rIhg7tkMLhrBv07Nqdemob8OEQFQkRqnYMHnYVf7eTT/AKmLd9K3uoiSsoOkpacRJ8OTRncNXKE0b117e5OqwIhIrXe3pIyZq8ujFy/WL6VJZt2AdAkPZWczpGji8Fdal93Wg21ISK1Xr20ZL59cibfPjkTgIJd+5mevzXSQyq/gL8u2AhAVvP0oFhkMrBz81rdnVZHECJS69Xm7rQ6xSQicgxKDhxk3rp/7U5bPy2Z/gnWnVYFQkTkBOzYW8pnK7YxLbjgvTp4pGrLRnW/0Z02s2GdkJMeOxUIEZFKtK6wmGn5kdNR01dsZXtUd9qzumYwuGsm/bKa1YjutCoQIiJxUnbQWfjVDj5dvpXp+d/sTpudFXSn7ZJJ99aNSKqG3WlVIEREqsjhutM2TU9lUJfIxe7q1J1W3VxFRKpI+e60W3btY0b+tn92p51fc7rT6ghCRKSKuDv5W4LutPmR7rTFQXfaM9o14awukesXvdo3IbWKHsGqU0wiItVQyYGDzF1bxLTghr356//ZnXZAp+ZfDwfSOTN+3WlVIEREaoAdxaV8tnLr1z2korvTHioWOV0yyGhQed1pQysQZjYEeAhIBp509wcP0+4K4BWgr7vnBfPuAW4EyoA73P3dI21LBUJEEk1VdKcNpUCYWTKwDDgfWA/kAle7+6Jy7RoCfwXSgLHunmdmpwEvAP2A1sAHwMnuXna47alAiEgii+5OO235VuasCbrTpiRxwWknMe6a3sf1uWH1YuoH5Lv7yiDEFGAYsKhcu/uB3wA/i5o3DJji7vuBVWaWH3zeZ3HMKyJSbSUnGT3bNqFn2ybcdk4XiksOMHtVIdOWb43b+FDxLBBtgHVR79cD/aMbmFlvoJ27/9XMflZu3Znl1m1TfgNmNgYYA9C+fftKii0iUv2lp6Vw9iktOPuUFnHbRmjDEppZEvAH4N+P9zPcfby7Z7t7dmZmZuWFExGRuB5BbADaRb1vG8w7pCHQA/g46L7VEphqZkMrsK6IiMRZPI8gcoGuZtbRzNKA4cDUQwvdfYe7Z7h7lrtnETmlNDToxTQVGG5mdcysI9AVmB3HrCIiUk7cjiDc/YCZjQXeJdLNdYK7LzSz+4A8d596hHUXmtlLRC5oHwBuO1IPJhERqXy6UU5EpBY7UjfXxHp2noiIVBoVCBERiUkFQkREYkqYaxBmVgCsOYGPyAC2VlKcyqRcx0a5jo1yHZtEzNXB3WPeSJYwBeJEmVne4S7UhEm5jo1yHRvlOja1LZdOMYmISEwqECIiEpMKxD+NDzvAYSjXsVGuY6Ncx6ZW5dI1CBERiUlHECIiEpMKhIiIxFSrCoSZDTGzpWaWb2Z3x1hex8xeDJbPMrOsapJrpJkVmNm8YLqpinJNMLMtZvblYZabmf05yD0/eABUdch1tpntiNpf/1VFudqZ2UdmtsjMFprZnTHaVPk+q2CuKt9nZlbXzGab2RdBrl/FaFPl38kK5grlOxlsO9nM5prZWzGWVe7+cvdaMREZUXYF0InI86+/AE4r1+aHwGPB6+HAi9Uk10hgXAj77FtAb+DLwyy/GHgHMGAAMKua5DobeCuE/dUK6B28bkjkmezl/y2rfJ9VMFeV77NgHzQIXqcCs4AB5dqE8Z2sSK5QvpPBtn8CPB/r36uy91dtOoL4+hnZ7l4CHHpGdrRhwNPB61eAcy14mlHIuULh7p8AhUdoMgx4xiNmAk3MrFU1yBUKd9/o7p8Hr3cBi/nXR+VW+T6rYK4qF+yD3cHb1GAq32umyr+TFcwVCjNrC3wXePIwTSp1f9WmAhHrGdnlvyRft3H3A8AOoHk1yAVwRXBK4hUzaxdjeRgqmj0MA4NTBO+YWfeq3nhwaN+LyF+f0ULdZ0fIBSHss+B0yTxgC/C+ux92f1Xhd7IiuSCc7+SfgLuAg4dZXqn7qzYViJrsTSDL3XsC7/PPvxAkts+JjC9zBvAw8EZVbtzMGgCvAj9y951Vue0jOUquUPaZu5e5+5lEHivcz8x6VMV2j6YCuar8O2lm3wO2uPuceG/rkNpUICrynOuv25hZCtAY2BZ2Lnff5u77g7dPAn3inKmiquWzw91956FTBO7+NpBqZhlVsW0zSyXyS/g5d38tRpNQ9tnRcoW5z4Jtbgc+AoaUWxTGd/KouUL6TuYAQ81sNZFT0d8xs2fLtanU/VWbCsQRn5EdmArcELy+EvjQg6s9YeYqd456KJFzyNXBVOD6oGfOAGCHu28MO5SZtTx03tXM+hH5/zzuv1SCbT4FLHb3PxymWZXvs4rkCmOfmVmmmTUJXtcDzgeWlGtW5d/JiuQK4zvp7ve4e1t3zyLye+JDd7+uXLNK3V9xeyZ1deMVe0b2U8BkM8snchF0eDXJdYeZDSXyfO5CIj0o4s7MXiDSuyXDzNYD9xK5YIe7Pwa8TaRXTj5QDIyqJrmuBG41swPAXmB4FRR6iPyFNwJYEJy/Bvg50D4qWxj7rCK5wthnrYCnzSyZSEF6yd3fCvs7WcFcoXwnY4nn/tJQGyIiElNtOsUkIiLHQAVCRERiUoEQEZGYVCBERCQmFQgREYlJBUIkYGYzgv9mmdk1lfzZP4+1LZHqTN1cRcoxs7OBn7r7945hnZRg7JvDLd/t7g0qIZ5IldERhEjAzA6N4PkgcFYwzv+Pg4HbfmtmucHgbDcH7c82s0/NbCqwKJj3hpnNschzBMYE8x4E6gWf91z0toI7qn9rZl+a2QIz+37UZ38cDAS3xMyei7rT+UGLPNthvpn9rir3kdQuteZOapFjcDdRRxDBL/od7t7XzOoA083svaBtb6CHu68K3o9298JgiIZcM3vV3e82s7HB4G/lXQ6cCZwBZATrfBIs6wV0B74CpgM5ZrYYuAzo5u5+aEgIkXjQEYTI0V1AZPykeUSGyW4OdA2WzY4qDhAZguELYCaRQdO6cmSDgReC0UM3A/8A+kZ99np3PwjMA7KIDN+8D3jKzC4nMlyHSFyoQIgcnQG3u/uZwdTR3Q8dQez5ulHk2sV5wMBg2Oy5QN0T2O7+qNdlwKHrHP2IPAzme8DfTuDzRY5IBULkX+0i8mjOQ94lMpBdKoCZnWxm9WOs1xgocvdiM+tG5JGih5QeWr+cT4HvB9c5Mok8TnX24YJZ5JkOjYMhuX9M5NSUSFzoGoTIv5oPlAWniiYBDxE5vfN5cKG4ALg0xnp/A24JrhMsJXKa6ZDxwHwz+9zdr42a/zowkMizyB24y903BQUmlobA/5lZXSJHNj85rp9QpALUzVVERGLSKSYREYlJBUJERGJSgRARkZhUIEREJCYVCBERiUkFQkREYlKBEBGRmP4/RP22wuedqqUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#params\n",
    "layers_dims = [784,30,1]\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "\n",
    "#executa o treinamento\n",
    "parameters = train_nn(mnist_data_sample, mnist_target_sample, layers_dims, learning_rate, epochs, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T11:18:23.578361Z",
     "start_time": "2021-05-13T11:18:23.558497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000000000000002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(mnist_data_sample, mnist_target_sample, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
